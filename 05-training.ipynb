{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Authors      : Aditya Jain and Safwan Jamal\n",
    "Date started : November 16, 2022\n",
    "About        : Convex Optimization project; training script\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from cifardataset import CIFARDataset\n",
    "from custom_cnn_one import CustomCNN\n",
    "from custom_cnn_two import CustomCNNTwo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device is cuda\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Available device is {device}')\n",
    "model = CustomCNNTwo(num_classes).to(device)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set      = './image_list_cifar/train_full.csv'\n",
    "num_epochs     = 70\n",
    "early_stopping = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "batch_size     = 4\n",
    "class_list     = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                  'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "train_root_dir = './cifar-10-images/train/'\n",
    "test_root_dir  = './cifar-10-images/test/'\n",
    "test_set       = './image_list_cifar/test.csv'\n",
    "\n",
    "train_data       = CIFARDataset(train_root_dir, train_set, class_list, transform)\n",
    "train_dataloader = DataLoader(train_data,batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "print(len(train_dataloader))\n",
    "\n",
    "test_data        = CIFARDataset(test_root_dir, test_set, class_list, transform)\n",
    "test_dataloader  = DataLoader(test_data,batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Optimizer and Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test accuracy improved to 10.0%\n",
      "Best test accuracy improved to 13.5%\n",
      "Best test accuracy improved to 17.5%\n",
      "Best test accuracy improved to 20.0%\n",
      "Best test accuracy improved to 25.25%\n",
      "Best test accuracy improved to 31.25%\n",
      "Best test accuracy improved to 36.25%\n",
      "Best test accuracy improved to 38.0%\n",
      "Best test accuracy improved to 39.0%\n",
      "Best test accuracy improved to 40.25%\n",
      "Best test accuracy improved to 41.0%\n",
      "The best test accuracy achieved is 41.0\n"
     ]
    }
   ],
   "source": [
    "best_test_accuracy = 0.0\n",
    "early_stop_count   = 0\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    # Model Training\n",
    "    model.train()\n",
    "    train_epoch_loss = 0.0\n",
    "    for image_batch, label_batch in train_dataloader:    \n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "        label_batch = label_batch.squeeze_()\n",
    "        \n",
    "        # Compute and apply gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs   = model(image_batch)  \n",
    "        t_loss    = loss_func(outputs, label_batch)\n",
    "        t_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_epoch_loss += t_loss.item()        \n",
    "        \n",
    "    print(f'Training loss for epoch {epoch+1} is {train_epoch_loss/len(train_dataloader)}')\n",
    "    \n",
    "    # Model Evaluation\n",
    "    model.eval()\n",
    "    total_samples   = 0.0\n",
    "    total_correct   = 0.0\n",
    "    for image_batch, label_batch in test_dataloader:    \n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)  \n",
    "        label_batch = label_batch.squeeze_()\n",
    "        outputs = model(image_batch)\n",
    "        \n",
    "        # Calculate batch accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += label_batch.size(0)\n",
    "        total_correct += (predicted == label_batch).sum().item()\n",
    "    curr_accuracy = (total_correct/total_samples)*100\n",
    "    print(f'Test accuracy for epoch {epoch+1} is {curr_accuracy}%')\n",
    "    \n",
    "    if curr_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = curr_accuracy\n",
    "        print(f'Best test accuracy improved to {best_test_accuracy}%')\n",
    "        early_stop_count = 0\n",
    "    else:\n",
    "        early_stop_count += 1\n",
    "        \n",
    "    if early_stop_count==early_stopping:\n",
    "        print(f'The best test accuracy achieved is {best_test_accuracy}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (milamoth_ai)",
   "language": "python",
   "name": "milamoth_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
