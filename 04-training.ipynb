{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/a/aditya.jain/.conda/envs/milamoth_ai/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Authors      : Aditya Jain and Safwan Jamal\n",
    "Date started : November 16, 2022\n",
    "About        : Convex Optimization project; training script\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from cifardataset import CIFARDataset\n",
    "from custom_cnn_one import CustomCNN\n",
    "from custom_cnn_two import CustomCNNTwo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device is cuda\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Available device is {device}')\n",
    "model = CustomCNNTwo(num_classes).to(device)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set      = './image_list_cifar/train_full.csv'\n",
    "num_epochs     = 70\n",
    "early_stopping = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "batch_size     = 4\n",
    "class_list     = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                  'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "train_root_dir = './cifar-10-images/train/'\n",
    "test_root_dir  = './cifar-10-images/test/'\n",
    "test_set       = './image_list_cifar/test.csv'\n",
    "\n",
    "train_data       = CIFARDataset(train_root_dir, train_set, class_list, transform)\n",
    "train_dataloader = DataLoader(train_data,batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "print(len(train_dataloader))\n",
    "\n",
    "test_data        = CIFARDataset(test_root_dir, test_set, class_list, transform)\n",
    "test_dataloader  = DataLoader(test_data,batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Optimizer and Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for epoch 1 is 2.30478236579895\n",
      "Test accuracy for epoch 1 is 14.75%\n",
      "Best test accuracy improved to 14.75%\n",
      "Training loss for epoch 2 is 2.30045321337382\n",
      "Test accuracy for epoch 2 is 13.750000000000002%\n",
      "Training loss for epoch 3 is 2.2810683142344157\n",
      "Test accuracy for epoch 3 is 14.499999999999998%\n",
      "Training loss for epoch 4 is 2.1907650044759115\n",
      "Test accuracy for epoch 4 is 21.0%\n",
      "Best test accuracy improved to 21.0%\n",
      "Training loss for epoch 5 is 2.0603837677637737\n",
      "Test accuracy for epoch 5 is 27.750000000000004%\n",
      "Best test accuracy improved to 27.750000000000004%\n",
      "Training loss for epoch 6 is 1.9833827250798544\n",
      "Test accuracy for epoch 6 is 27.750000000000004%\n",
      "Training loss for epoch 7 is 1.8973989140192669\n",
      "Test accuracy for epoch 7 is 28.499999999999996%\n",
      "Best test accuracy improved to 28.499999999999996%\n",
      "Training loss for epoch 8 is 1.8438198628425597\n",
      "Test accuracy for epoch 8 is 28.999999999999996%\n",
      "Best test accuracy improved to 28.999999999999996%\n",
      "Training loss for epoch 9 is 1.7743852791786194\n",
      "Test accuracy for epoch 9 is 33.5%\n",
      "Best test accuracy improved to 33.5%\n",
      "Training loss for epoch 10 is 1.7285715540250142\n",
      "Test accuracy for epoch 10 is 35.5%\n",
      "Best test accuracy improved to 35.5%\n",
      "Training loss for epoch 11 is 1.684030218442281\n",
      "Test accuracy for epoch 11 is 37.75%\n",
      "Best test accuracy improved to 37.75%\n",
      "Training loss for epoch 12 is 1.6191209230422974\n",
      "Test accuracy for epoch 12 is 31.25%\n",
      "Training loss for epoch 13 is 1.5790286634763082\n",
      "Test accuracy for epoch 13 is 38.75%\n",
      "Best test accuracy improved to 38.75%\n",
      "Training loss for epoch 14 is 1.5248021725813548\n",
      "Test accuracy for epoch 14 is 35.75%\n",
      "Training loss for epoch 15 is 1.446204444328944\n",
      "Test accuracy for epoch 15 is 37.0%\n",
      "Training loss for epoch 16 is 1.404180531024933\n",
      "Test accuracy for epoch 16 is 42.0%\n",
      "Best test accuracy improved to 42.0%\n",
      "Training loss for epoch 17 is 1.3209106787045797\n",
      "Test accuracy for epoch 17 is 33.75%\n",
      "Training loss for epoch 18 is 1.2750864130258561\n",
      "Test accuracy for epoch 18 is 41.25%\n",
      "Training loss for epoch 19 is 1.206012943148613\n",
      "Test accuracy for epoch 19 is 37.75%\n",
      "Training loss for epoch 20 is 1.0946725523471832\n",
      "Test accuracy for epoch 20 is 33.5%\n",
      "Training loss for epoch 21 is 1.0178514462908108\n",
      "Test accuracy for epoch 21 is 37.0%\n",
      "Training loss for epoch 22 is 0.9354706729849179\n",
      "Test accuracy for epoch 22 is 42.0%\n",
      "Training loss for epoch 23 is 0.8012313333749771\n",
      "Test accuracy for epoch 23 is 37.5%\n",
      "Training loss for epoch 24 is 0.7506069613695144\n",
      "Test accuracy for epoch 24 is 36.5%\n",
      "The best test accuracy achieved is 42.0\n"
     ]
    }
   ],
   "source": [
    "best_test_accuracy = 0.0\n",
    "early_stop_count   = 0\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    # Model Training\n",
    "    model.train()\n",
    "    train_epoch_loss = 0.0\n",
    "    for image_batch, label_batch in train_dataloader:    \n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "        label_batch = label_batch.squeeze_()\n",
    "        \n",
    "        # Compute and apply gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs   = model(image_batch)  \n",
    "        t_loss    = loss_func(outputs, label_batch)\n",
    "        t_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_epoch_loss += t_loss.item()        \n",
    "        \n",
    "    print(f'Training loss for epoch {epoch+1} is {train_epoch_loss/len(train_dataloader)}')\n",
    "    \n",
    "    # Model Evaluation\n",
    "    model.eval()\n",
    "    total_samples   = 0.0\n",
    "    total_correct   = 0.0\n",
    "    for image_batch, label_batch in test_dataloader:    \n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)  \n",
    "        label_batch = label_batch.squeeze_()\n",
    "        outputs = model(image_batch)\n",
    "        \n",
    "        # Calculate batch accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += label_batch.size(0)\n",
    "        total_correct += (predicted == label_batch).sum().item()\n",
    "    curr_accuracy = (total_correct/total_samples)*100\n",
    "    print(f'Test accuracy for epoch {epoch+1} is {curr_accuracy}%')\n",
    "    \n",
    "    if curr_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = curr_accuracy\n",
    "        print(f'Best test accuracy improved to {best_test_accuracy}%')\n",
    "        early_stop_count = 0\n",
    "    else:\n",
    "        early_stop_count += 1\n",
    "        \n",
    "    if early_stop_count==early_stopping:\n",
    "        print(f'The best test accuracy achieved is {best_test_accuracy}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying out AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mila/a/aditya.jain/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "list(model.children())[:3, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (milamoth_ai)",
   "language": "python",
   "name": "milamoth_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
